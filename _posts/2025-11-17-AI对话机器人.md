---
layout:     post
title:      AI 对话机器人技术栈
subtitle:   AI
date:       2025-11-17
author:     LXG
header-img: img/google_android.jpg
catalog: true
tags:
    - AI
---

[EmpathyEar](https://github.com/scofield7419/EmpathyEar)

## 架构图

```swift

┌──────────────────────────────────────────────┐
│                  用户（孩子）                 │
│        说话 → 麦克风 → 语音输入               │
└──────────────────────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────┐
│         语音采集模块（Android AudioRecord）   │
│  - 降噪/回声消除/端点检测（VAD）              │
└──────────────────────────────────────────────┘
                            │ PCM音频流
                            ▼
┌──────────────────────────────────────────────┐
│      科大讯飞 SDK（离线/在线语音识别 ASR）     │
│  - 把语音 → 文本                              │
└──────────────────────────────────────────────┘
                            │ 文本
                            ▼
┌──────────────────────────────────────────────┐
│               对话管理模块（核心）             │
│  - 调用云端大模型（如 讯飞星火 2.0）           │
│  - 或者使用本地轻量模型（如 ChatGLM-mini）     │
│  - 意图识别                                    │
│  - 情绪判断（决定玩具的表情）                  │
│  - 状态管理（上下文记忆）                      │
└──────────────────────────────────────────────┘
                            │ 文本 + 情绪值
                            ▼
┌──────────────────────────────────────────────┐
│           表情控制模块（Emotion Engine）       │
│  - 表情标签：开心/疑惑/思考/生气/睡眠…         │
│  - 对应动画文件：Lottie / GIF / MP4 /帧动画    │
│  - 输出给 Android UI 层                        │
└──────────────────────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────┐
│                  安卓 UI 层                    │
│   - SurfaceView / TextureView 播放动画         │
│   - 显示表情                                   │
└──────────────────────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────┐
│                TTS 合成（讯飞 TTS）            │
│   - 文本 → 声音                               │
│   - 可配置音色、情绪、语速                     │
└──────────────────────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────┐
│           扬声器播放（AudioTrack）             │
│     → 小朋友听到玩具的回答                     │
└──────────────────────────────────────────────┘

```

## 技术栈

| 模块                | 具体功能          | 使用技术                                  | 可选替代方案                             |
| ----------------- | ------------- | ------------------------------------- | ---------------------------------- |
| **音频采集**          | 麦克风录音、实时语音流   | AudioRecord、OpenSL ES、AEC 回声消除、降噪（NS） | SpeexDSP、WebRTC 音频处理               |
| **唤醒词**（可选）       | 离线唤醒“你好小宝”等   | 科大讯飞离线唤醒、思必驰 DuerOS、Snowboy（停更但可用）    | Picovoice Porcupine                |
| **ASR 语音识别**      | 语音转文字         | **科大讯飞 ASR SDK**、Google Speech（需梯子）   | Whisper（本地版，需高性能 SOC）              |
| **对话引擎（大模型）**     | 聊天对话、情绪提取     | 星火大模型、ChatGPT API、GLM API             | 本地模型：Qwen2.5 1.5B、RWKV、MNN-LLM     |
| **意图理解（NLU）**     | 识别需求：讲故事、问天气等 | 自定义规则 + BERT 分类、小模型 NLU               | ChatGPT 直接解析                       |
| **对话管理（DM）**      | 上下文、状态机、角色人格  | 自研管理器（Kotlin）、Rasa（偏重）                | LLM function-call                  |
| **TTS 语音合成**      | 文本 → 玩具语音     | **科大讯飞 TTS**、火山 TTS、微软 TTS            | 离线 TTS（Piper / VITS）               |
| **音频播放**          | 播放合成语音        | AudioTrack、MediaPlayer                | OpenSL ES                          |
| **表情检测 / 情绪引擎**   | 将对话内容映射到表情    | NLP 情绪分析模型、关键词规则、LLM 输出情绪标签           | 自研分类器（SVM / TinyBERT）              |
| **表情动画引擎**        | 控制屏幕显示表情      | Lottie、帧动画、GIF、Canvas 动画              | Unity（嵌入 Android）、Three.js WebView |
| **嘴型同步（LipSync）** | 让角色嘴巴跟声音同步    | 分析 TTS 音素 → 动画                        | Rhubarb LipSync、音量阈值驱动             |
| **Avatar（可选）**    | 3D 卡通人物 ／ 数字人 | Unity Avatar、ChatdollKit、Three.js     | 静态 PNG + 动画帧                       |
| **网络通信**          | 和服务器 / 云端模型通信 | Retrofit、OkHttp、WebSocket             | gRPC                               |
| **本地存储**          | 存历史对话/配置      | Room、MMKV、SP                          | LitePal                            |
| **后台常驻服务**        | 常驻录音 / 唤醒线程   | Foreground Service、JobService         | AIDL 进程保活（不建议太激进）                  |
| **系统层适配**         | 读写麦克风权限、保活    | Android 权限管理、Power Manager            | Framework 修改（如定制系统）                |
| **OTA 升级（可选）**    | 模型或素材更新       | 自研 OTA、基于文件的差分升级                      | Firebase OTA（国内不适用）                |
| **硬件交互**（可选）      | 触摸、重力、按钮      | SensorManager、GPIO（JNI）               | N/A                                |
| **渲染性能优化**        | 降低 GPU/CPU 占用 | 硬件加速、SurfaceView、动态图缓存                | NDK 优化、局部刷新                        |

## 核心实现难点

| 模块                | 技术难点             | 详细说明                                                                 |
| ----------------- | ---------------- | -------------------------------------------------------------------- |
| **语音识别（ASR）**     | 离线高准确率、噪声环境适应    | 玩具环境噪声大（孩子说话、背景音乐），离线讯飞 SDK 需要调参、使用回声消除/降噪，否则识别率下降                   |
| **语音合成（TTS）**     | 情绪/语气控制、本地延迟     | 玩具对“情绪共情”有要求，本地 TTS 合成音色自然且延迟低比较难，需要调语速、音量、音色                        |
| **本地轻量 LLM**      | 模型压缩、推理速度        | 小型 Qwen 模型需要量化/剪枝 + NPU 加速，否则推理延迟会影响交互体验                             |
| **云端大模型调用**       | 异步设计、上下文管理       | 网络延迟 + API调用时间不可控，需要设计先用本地模型快速响应 → 云端结果替换机制，保证对话流畅且上下文连续             |
| **表情动画 / avatar** | 实时同步、帧率、动画自然     | 需要表情与语音同步，嘴型、眼睛、表情动作协调；复杂 3D avatar 在 RK3568 GPU 上渲染性能有限，需要优化帧率和渲染方式 |
| **多模态融合**         | 协调语音、表情、对话       | 用户说话 → ASR → LLM → TTS → avatar表情 → 播放音频，整个流水线的时间同步和逻辑顺序设计比较复杂       |
| **安卓系统集成**        | 权限、线程、性能         | 安卓 APK 同时处理麦克风、扬声器、屏幕渲染和网络请求，需要合理线程调度和异步处理，否则容易 ANR 或掉帧              |
| **硬件限制**          | CPU/GPU/NPU/内存瓶颈 | RK3568 或 A133 性能有限，本地模型和动画渲染可能同时占用资源，容易出现卡顿，需要优化推理速度和渲染负载            |
| **多轮上下文管理**       | 对话连贯性            | 玩具需要短期/长期上下文跟踪，实现本地 + 云端对话融合，设计缓存策略和状态管理较复杂                          |
| **离线体验保证**        | 无网状态 fallback    | 当网络不稳定或断网时，需要保证本地轻量模型 +表情动画依然可用，否则玩具就“静音”或没反应                        |
| **开发调试**          | 模块联调复杂           | 多 SDK（讯飞 ASR/TTS + LLM API）+动画渲染 +安卓线程 +网络调用，整体联调难度高，容易出现同步问题        |

## 什么是回声消除

在语音通信或语音交互场景中，回声指的是麦克风捕捉到的扬声器播放的声音，并被当成用户的声音重复传输给远端或语音处理模块

```sql

+-------------------+
|  麦克风采集信号   |  <-- 包含用户语音 + 扬声器回声 + 环境噪声
+---------+---------+
          |
          v
+-------------------+
|  回声预测 (Adaptive Filter) |
|  输入: 扬声器播放信号 x[n] |
|  输出: 预测回声 h[n]*x[n] |
+---------+---------+
          |
          v
+-------------------+
|  回声消除 (Subtraction) |
|  y[n] - h[n]*x[n]        |
|  输出: 麦克风干净语音 ŝ[n] |
+---------+---------+
          |
          v
+-------------------+
|  残余回声抑制 (Non-linear Processing) |
|  减少自适应滤波未完全消除的回声       |
+---------+---------+
          |
          v
+-------------------+
|  可选: 降噪处理 (Noise Suppression)   |
|  输出: 干净语音输入 ASR / AI 模型     |
+-------------------+

```

## 回声消除方案

| 场景                  | 推荐方案                  | 是否够用                        |
| ------------------- | --------------------- | --------------------------- |
| 单麦克风语音玩具 / TTS 回声消除 | SpeexDSP / WebRTC AEC | ✅ 完全够用                      |
| 低延迟、高性能语音对话 App     | WebRTC AEC + DSP      | ✅ 可以，延迟低                    |
| 多麦克风阵列 + AI 语音对话    | AEC + 波束形成 + 可选神经网络增强 | ⚠️ CPU 可能吃力，建议使用 NPU/DSP 加速 |

**回声消除库**

```bash

libagora_ai_echo_cancellation_extension.so     libagora-rtc-sdk.so                           libaosl.so                 libcutils.so                     libSparkChain.so
libagora_ai_echo_cancellation_ll_extension.so  libagora_screen_capture_extension.so          libarcsoft_face_engine.so  libeasyopus.so                   libspark.so
libagora_ai_noise_suppression_extension.so     libagora_segmentation_extension.so            libarcsoft_face.so         libfifo.so                       libtensorflow_inference.so
libagora_ai_noise_suppression_ll_extension.so  libagora-soundtouch.so                        libarcsoft_image_util.so   libhlw.so                        libtensorflowlite_jni.so
libagora_audio_beauty_extension.so             libagora_spatial_audio_extension.so           libaudio_mix.so            libimage_processing_util_jni.so  libtinyalsa.so
libagora_clear_vision_extension.so             libagora_video_av1_decoder_extension.so       libbacktrace.so            libkws.so                        libunwind.so
libagora_content_inspect_extension.so          libagora_video_av1_encoder_extension.so       libbarhopper_v3.so         liblzma.so                       libutils.so
libagora_face_capture_extension.so             libagora_video_decoder_extension.so           libbase.so                 libnative-lib.so                 libvideo_dec.so
libagora_face_detection_extension.so           libagora_video_encoder_extension.so           libbfJni.so                libopusenc.so                    libvideo_enc.so
libagora-fdkaac.so                             libagora_video_quality_analyzer_extension.so  libcae-jni.so              libopus.so                       libvtn.so
libagora-ffmpeg.so                             libaiui.so                                    libcae.so                  libsdk_license.so                libxxl.so
libagora_lip_sync_extension.so                 libalsa-jni.so                                libc++.so                  libsdk_omni.so

```

| 库名                                              | 注释说明                            |
| ----------------------------------------------- | ------------------------------- |
| `libagora_ai_echo_cancellation_extension.so`    | Agora AI 回声消除库（普通延迟版本）          |
| `libagora_ai_echo_cancellation_ll_extension.so` | Agora AI 回声消除库（低延迟版本）           |
| `libagora_ai_noise_suppression_extension.so`    | Agora AI 噪声抑制库                  |
| `libagora_ai_noise_suppression_ll_extension.so` | Agora AI 噪声抑制库（低延迟版本）           |
| `libagora_audio_beauty_extension.so`            | Agora 音频美声处理库（声音美化、音色调整）        |
| `libagora_clear_vision_extension.so`            | 视频清晰度增强或美化处理库（闭源）               |
| `libagora_content_inspect_extension.so`         | 内容审核/智能检测库（闭源）                  |
| `libagora_face_capture_extension.so`            | 人脸捕捉 / 识别采集库（闭源）                |
| `libagora_face_detection_extension.so`          | 人脸检测库（闭源）                       |
| `libagora-fdkaac.so`                            | FDK AAC 音频编码库（开源或集成第三方 AAC 编码器） |
| `libagora-ffmpeg.so`                            | FFmpeg 库，视频编解码、格式处理             |
| `libagora_lip_sync_extension.so`                | AI 唇语同步库（闭源）                    |
| `libagora_screen_capture_extension.so`          | 屏幕采集扩展库                         |
| `libagora_segmentation_extension.so`            | 视频分割 / 虚拟背景库（闭源）                |
| `libagora-soundtouch.so`                        | 音频变速 / 变调处理库（SoundTouch 开源封装）   |
| `libagora_spatial_audio_extension.so`           | 空间音频处理库（3D 音效）                  |
| `libagora_video_av1_decoder_extension.so`       | AV1 视频解码器扩展                     |
| `libagora_video_av1_encoder_extension.so`       | AV1 视频编码器扩展                     |
| `libagora_video_decoder_extension.so`           | 视频解码器扩展库                        |
| `libagora_video_encoder_extension.so`           | 视频编码器扩展库                        |
| `libagora_video_quality_analyzer_extension.so`  | 视频质量分析库                         |
| `libagora-rtc-sdk.so`                           | 核心 RTC SDK 库（音视频通话、实时通信功能）      |
| `libaosl.so`                                    | 未知，闭源库，可能是 Agora 内部音频/视频处理库     |
| `libarcsoft_face_engine.so`                     | ArcSoft 人脸引擎库（人脸识别/属性分析）        |
| `libarcsoft_face.so`                            | ArcSoft 人脸库，功能类似 face_engine    |
| `libarcsoft_image_util.so`                      | ArcSoft 图像处理工具库                 |
| `libaudio_mix.so`                               | 音频混合库（将多路音频混合到一起）               |
| `libaiui.so`                                    | 科大讯飞 AIUI 库（语音识别、语义理解）          |
| `libalsa-jni.so`                                | ALSA 音频驱动 JNI 封装库（安卓底层音频接口）     |
| `libbacktrace.so`                               | 调试工具库，提供栈回溯功能                   |
| `libbfJni.so`                                   | 未知，闭源，可能是内部 JNI 封装              |
| `libbase.so`                                    | 通用基础库，闭源或内部 SDK 依赖              |
| `libcae.so` / `libcae-jni.so`                   | CAE 声学回声引擎库（Agora 内部音频处理）       |
| `libeasyopus.so`                                | Opus 音频编码/解码库封装                 |
| `libfifo.so`                                    | FIFO 队列库，音视频数据缓存使用              |
| `libhlw.so`                                     | 未知，闭源库                          |
| `libimage_processing_util_jni.so`               | 图像处理工具 JNI 封装                   |
| `libkws.so`                                     | 关键词唤醒（Keyword Spotting）库        |
| `liblzma.so`                                    | LZMA 压缩库（开源）                    |
| `libnative-lib.so`                              | 通用 JNI 库，可能是项目自定义 C/C++ 接口      |
| `libopus.so` / `libopusenc.so`                  | Opus 音频编解码库                     |
| `libsdk_license.so`                             | SDK 授权/许可管理库                    |
| `libsdk_omni.so`                                | 未知，闭源，可能是 SDK 内部通用功能库           |
| `libSparkChain.so` / `libspark.so`              | 未知，闭源，可能是 AI / 视频渲染链相关库         |
| `libtensorflow_inference.so`                    | TensorFlow C++ 推理库              |
| `libtensorflowlite_jni.so`                      | TensorFlow Lite JNI 封装库，用于安卓推理  |
| `libtinyalsa.so`                                | TinyALSA 音频接口库（嵌入式 / 安卓音频）      |
| `libunwind.so`                                  | 调试 / 异常回溯库（stack unwind）        |
| `libutils.so` / `libcutils.so`                  | 安卓基础工具库（ADB、日志、字符串工具等）          |
| `libvideo_dec.so` / `libvideo_enc.so`           | 视频解码/编码自定义库（可能封装 FFmpeg 或硬件）    |
| `libvtn.so` / `libxxl.so`                       | 未知，闭源库                          |

**声网**

[消除播放媒体资源产生的回声](https://docs-legacy.agora.io/cn/dual-teacher/indoor_echo_cancellation?platform=Windows)

## 开源 AEC 库 vs Agora

| 对比维度      | **开源 AEC 库**（SpeexDSP / WebRTC AEC） | **Agora AEC 库**（libagora_ai_echo_cancellation_extension.so） |
| --------- | ----------------------------------- | ----------------------------------------------------------- |
| **源代码**   | ✅ 开源，可修改、调试和优化                      | ❌ 闭源，不可修改                                                   |
| **许可/费用** | ✅ 免费开源，MIT/GPL 等                    | ❌ 需要 Agora SDK，按使用条款（可能有收费）                                 |
| **集成难度**  | 中等，需要 NDK/ JNI 封装                   | 低，直接集成 .so + SDK API                                        |
| **算法性能**  | 较成熟，延迟低，但需要手动调参                     | 优化良好，低延迟、高精度、支持 AI 增强                                       |
| **延迟**    | 取决于算法和 CPU 性能，一般 10–30ms            | 优化极好，低延迟版本 LL（Low Latency）可满足实时对话需求                         |
| **资源消耗**  | CPU 占用中等，可控                         | CPU 占用低，内部做了硬件/算法优化                                         |
| **特性**    | 基本回声消除 + 可选残余回声抑制                   | 回声消除 + AI 增强 + 噪声抑制，可选低延迟版本                                 |
| **平台支持**  | 安卓/iOS/Linux/嵌入式                    | 安卓/iOS（Agora 官方 SDK 支持）                                     |
| **可扩展性**  | 高，可定制滤波器长度、算法结构                     | 受限，不能修改内部算法，只能使用 SDK 提供功能                                   |
| **适合场景**  | 学术、开源项目、小型玩具、低成本嵌入式设备               | 商业产品、对话玩具、低延迟语音交互、对 AI 体验要求高                                |

## SpeexDSP vs WebRTC AEC

| 对比维度           | **SpeexDSP AEC**              | **WebRTC AEC**                   |
| -------------- | ----------------------------- | -------------------------------- |
| **开源状态**       | ✅ 完全开源（BSD/GPL）               | ✅ 完全开源（BSD）                      |
| **算法类型**       | 传统自适应滤波 + 残余回声抑制              | 传统自适应滤波 + 非线性处理 + 延迟估计优化         |
| **延迟性能**       | 较低，一般 10–20ms                 | 较低，优化更好，尤其在低延迟模式下（AECM / AEC3）   |
| **残余回声处理**     | 基本处理，简单谱减                     | 更强的残余回声抑制，算法更成熟                  |
| **噪声抑制能力**     | 无自带噪声抑制，需要结合 SpeexDSP NS 或其他库 | 内置 NS（Noise Suppression）模块，可同时使用 |
| **集成难度**       | 较低，C 库，NDK 编译即可               | 中等，需要提取 AEC 模块，编译依赖 WebRTC 编译链   |
| **资源消耗**       | 轻量，CPU 占用低                    | 略高，但优化较好，延迟和 CPU 可控              |
| **支持采样率**      | 8/16 kHz                      | 8/16 kHz，WebRTC AEC3 支持更高采样率     |
| **多通道 / 波束形成** | 不支持，需要自己实现                    | WebRTC 提供扩展接口，可结合多麦阵列            |
| **平台适配**       | 安卓 / iOS / Linux / 嵌入式        | 安卓 / iOS / Linux / 嵌入式           |
| **使用场景**       | 单麦克风语音对话、低资源设备、学术/开源项目        | 低延迟语音通话、多人会议、AI 对话玩具、复杂声学环境      |
| **优点**         | 超轻量、简单、易调试、延迟低                | 算法成熟、残余回声抑制强、低延迟模式优化好、支持多麦阵列     |
| **缺点**         | 算法简单，对混响环境效果一般                | 编译和集成稍复杂，库大                      |


## 开源项目

[Android-Audio-Processing-Using-WebRTC](https://github.com/mail2chromium/Android-Audio-Processing-Using-WebRTC)


























