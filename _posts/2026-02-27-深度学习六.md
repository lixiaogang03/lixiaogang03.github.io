---
layout:     post
title:      深度学习六
subtitle:   数学基础
date:       2026-02-27
author:     LXG
header-img: img/post-bg-digital_circuits.jpg
catalog: true
tags:
    - AI
---

## AI 开发框架

| 框架               | 核心特点                     | 开发语言             | 主要应用场景                        | 生态 / 社区               |
| ---------------- | ------------------------ | ---------------- | ----------------------------- | --------------------- |
| **PyTorch**      | 动态图，调试友好；2.0+ 编译器优化      | Python, C++      | 科研、生成式 AI、LLM、CV/NLP          | 全球最活跃，Hugging Face 支持 |
| **TensorFlow**   | 静态/混合图；成熟工业部署链 (TFX)     | Python, C++, JS  | 工业化生产、移动端、Web AI              | 社区庞大，Google 官方支持      |
| **JAX**          | 函数式编程，Autograd + XLA 高性能 | Python (C++)     | 大规模模型预训练、科研、强化学习              | Google 内部主力，科研圈扩展快    |
| **PaddlePaddle** | 国产自研；动静统一，官方产业模型丰富       | Python, C++      | 本土工业应用、安防、推荐、OCR              | 百度主导，中文社区活跃           |
| **MindSpore**    | 昇腾硬件优化；全场景统一架构           | Python, C++      | 国产 AI 芯片、AI for Science、政务/能源 | 华为支持，国内大模型训练关键支撑      |
| **MxNet**        | 高性能，动静混合图 (Gluon)；轻量化    | Python, R, Scala | 云端部署、大模型训练                    | 亚马逊支持，社区活跃度下降         |

TensorFlow 和 PyTorch 是 主要竞争关系，尤其在科研 vs 工业落地领域有不同优势，但两者在生态上也能通过 ONNX、模型导出 等方式互通。

PyTorch 更强调科研灵活性和动态图调试，工业部署虽然可以（TorchScript + ONNX），但生态和工业化工具链不如 TensorFlow 完整。

![pytorch_vs_tesorflow](/images/ai/pytorch_vs_tesorflow.png)

## TensorFlow

TensorFlow 主要由 Google 官方主导开发和维护，同时有全球开源社区协作

TensorFlow 适合工业场景的核心原因：

1. 静态/混合图优化 → 高效、稳定推理
2. 完整工业部署链 → TFX、Serving、Lite、JS
3. 跨平台支持 → CPU/GPU/TPU/移动/边缘
4. 企业级工具 → 版本管理、监控、分布式训练
5. 社区和官方支持 → 稳定性和长期维护

**安装**

```bash

# 安装最新稳定版 TensorFlow CPU 版本
pip install tensorflow

```

**查看版本**

```py

import tensorflow as tf

# 打印 TensorFlow 版本和可用 GPU 信息
print("TensorFlow 版本:", tf.__version__)

print("可用 GPU:", tf.config.list_physical_devices('GPU'))

```

**运行结果**

```bash

TensorFlow 版本: 2.20.0
可用 GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1772164609.724609  308356 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4643 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6


```

### 入门

```py

import tensorflow as tf

x = tf.range(12)  # 创建一个包含12个元素的一维张量
print(x)  # 打印张量的内容
print(x.shape)  # 打印张量的形状
print(tf.size(x))  # 打印张量的元素总数

X = tf.reshape(x, (3, 4))  # 将一维张量重新形状为3行4列的二维张量
print(X)

```

## Pytorch

PyTorch 主要由 Facebook（现 Meta Platforms） 主导开发和维护，同时有活跃的开源社区参与

**Pytorch 和 CUDA 关系**

![pytorch_cuda](/images/ai/pytorch_cuda.png)

**AMD的角色**

| 框架             | 支持情况            | 说明                                                                                   |
| -------------- | --------------- | ------------------------------------------------------------------------------------ |
| **PyTorch**    | 支持 AMD ROCm GPU | PyTorch 官方提供 ROCm 分支（`pip install torch --rocm`），可以在 AMD GPU 上运行训练和推理。               |
| **TensorFlow** | 支持有限            | TensorFlow 官方 GPU 版本主要针对 CUDA/NVIDIA，但社区有 AMD ROCm 分支（`tensorflow-rocm`），用于 AMD GPU。 |

### 入门

```py

import torch

# 创建一个包含12个元素的一维张量
x = torch.arange(12)
# 打印张量的内容、形状和元素总数
print(x)
print(x.shape)
print(x.numel())

# 将一维张量重新形状为3行4列的二维张量
x = x.reshape(3, 4)
print(x)

x = torch.zeros((2, 3))  # 创建一个2行3列的全零张量
print(x)
x = torch.ones((2, 3))   # 创建一个2行3列的全一
print(x)
x = torch.randn((2, 3))  # 创建一个2行3列的随机张量，元素服从标准正态分布
print(x)

```

### 运算符

```py

import torch

torch.set_default_device('cuda' if torch.cuda.is_available() else 'cpu')  # 设置默认设备为GPU（如果可用）或CPU

x = torch.tensor([1.0, 2, 4, 8])  # 从Python列表创建一个张量
y = torch.tensor([2, 2, 2, 2]) # 从Python列表创建另一个张量
print(x + y)  # 张量加法
print(x - y)  # 张量减法
print(x * y)  # 张量乘法（逐元素乘法）
print(x / y)  # 张量除法（逐元素除法）
print(x ** y) # 张量幂运算（逐元素指数运算）

# e 是自然对数的底数，约等于2.71828
print(torch.exp(x))  # 计算张量的指数

```

**运算结果**

```bash

tensor([ 3.,  4.,  6., 10.], device='cuda:0')
tensor([-1.,  0.,  2.,  6.], device='cuda:0')
tensor([ 2.,  4.,  8., 16.], device='cuda:0')
tensor([0.5000, 1.0000, 2.0000, 4.0000], device='cuda:0')
tensor([ 1.,  4., 16., 64.], device='cuda:0')
tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03], device='cuda:0')

```

#### 自然对数e

e ≈ 2.718，是连续增长的极限, 想象钱不停地复利增长，它就会变成 e 倍增长。

![math_e](/images/ai/math_e.png)

![math_e_1](/images/ai/math/math_e_1.png)

1. `增长有上限`： 即使你把 100% 的利率拆分得再细（每微秒结算一次），你最终能得到的钱也不会超过初始资金的 2.71828 倍。$e$ 就是这个“自然增长率”的极限。
2. `平滑性`： $e^x$ 是唯一一个在 $x=0$ 时斜率为 $1$ 且增长率始终等于当前值的指数函数。
3. `计算意义`： 在 Python 中，np.exp(x) 比 2.718**x 更精确且运行更快，因为它是底层 CPU 针对指数运算专门优化过的。

**无论 $x$ 取什么值，$e^x$ 的“高度”和“斜率”始终是同步的。**

![math_e_2](/images/ai/math/math_e_2.png)

1. `高度与斜率的统一`：你会看到点 $(1, 2.7183)$ 的 $y$ 值，正好和红字标出的 Slope 一模一样。
2. `视觉验证`：切线正好贴着红点而过。在数学上，这意味着在这一个瞬间，函数变化的“速度”和它当下的“规模”达成了完美的共振。








































 


