---
layout:     post
title:      深度学习
subtitle:   基于Python的研究和实现
date:       2026-02-09
author:     LXG
header-img: img/post-bg-digital_circuits.jpg
catalog: true
tags:
    - AI
    - 职业
---

## 查看系统中的python版本

```bash

lxg@lxg:~/code$ ls -al /usr/bin/python*
lrwxrwxrwx 1 root root      16  6月  3  2025 /usr/bin/python -> /usr/bin/python2
lrwxrwxrwx 1 root root       9  7月 28  2021 /usr/bin/python2 -> python2.7
-rwxr-xr-x 1 root root 3592536 12月 10  2024 /usr/bin/python2.7
lrwxrwxrwx 1 root root      10 11月 26  2024 /usr/bin/python3 -> python3.10
-rwxr-xr-x 1 root root 5937672  1月  8 14:52 /usr/bin/python3.10

```

## NumPy

numpy 是 Python 里最重要的科学计算库之一，主要用来：

* 数组运算（比 list 快很多）
* 矩阵计算
* 数学运算（线性代数、随机数等）
* 深度学习底层计算（PyTorch、TensorFlow 都依赖它）

```py

# 导入 Python 的 numpy 库，并把它起一个简写名字 np 使用
import numpy as np

def main():
    # Create a 3x3 array of random floats between 0 and 1
    array = np.random.rand(3, 3)
    
    # Print the array
    print("3x3 Array of Random Floats:")
    print(array)


if __name__ == "__main__":
    main()

```

NumPy 数组可以生成N维数组，数学上将一维数组称为**向量**， 二维数组称为**矩阵**，多维数组称为**张量**

| 名称     | 维度  | 例子            |
| ------ | --- | ------------- |
| **标量** | 0维  | 5             |
| **向量** | 1维  | [1,2,3]       |
| **矩阵** | 2维  | [[1,2],[3,4]]   比如：表格 |
| **张量** | ≥3维 | 多维数组    比如：图片、视频、batch   |

**广播**不同维度数组之间的计算

## Python VS C++

| 项    | Python    | C++       |
| ---- | --------- | --------- |
| 类型   | 解释型       | 编译型       |
| 语法   | 简单        | 复杂        |
| 开发效率 | 非常高       | 较低        |
| 执行速度 | 慢         | 非常快       |
| 内存控制 | 自动        | 手动        |
| 学习成本 | 低         | 高         |
| 适合人群 | 数据/AI/自动化 | 系统/性能/嵌入式 |

**C++ 速度 = Python 的 10~100 倍**

## Matplotlib

Matplotlib 是 Python 最常用的数据可视化库，用来画图

| 函数            | 作用   |
| ------------- | ---- |
| plt.plot()    | 折线图  |
| plt.scatter() | 散点图  |
| plt.bar()     | 柱状图  |
| plt.imshow()  | 显示图像 |
| plt.title()   | 标题   |
| plt.xlabel()  | x轴   |
| plt.ylabel()  | y轴   |
| plt.legend()  | 图例   |
| plt.show()    | 显示图  |

```python

import numpy as np

import matplotlib.pyplot as plt

# 生成数据
x = np.arange(0, 6, 0.1)
y = np.sin(x)

# 创建图形
plt.plot(x, y)
plt.title("Sine Wave")
plt.xlabel("X Axis")
plt.ylabel("Y Axis")
plt.show()

```

**运行后生成图形**

![python_matplotlib](/images/ai/python_matplotlib.png)

## 显示图像

```py

import numpy as np

import matplotlib.pyplot as plt

from matplotlib.image import imread

img= imread('car.jpg')
plt.imshow(img)

plt.show()

```

**运行后显示结果**

![python_matplotlib_image](/images/ai/python_matplotlib_image.png)

## 感知机

感知机就是一个“会加权判断的神经元”，深度学习的所有复杂神经网络都是由无数个感知机堆起来的

**感知机的数学公式**

```markdown

y=f(w1​x1​+w2​x2​+...+wn​xn​+b)

```

| 符号              | 含义                          |
| --------------- | --------------------------- |
| x1, x2, ..., xn | 输入特征                        |
| w1, w2, ..., wn | 权重（代表每个特征的重要性）              |
| b               | 偏置（可以调整阈值）                  |
| f()             | 激活函数，通常是阶跃函数（大于0就输出1，否则输出0） |
| y               | 输出（1 或 0）                   |

权重相当于电流中的电阻， 电阻是决定电流流动难度的参数，电阻越低通过的电流越大。感知机则是权重越大，通过的信号就越大

### 简单逻辑电路

| x1 | x2 | y |
| -- | -- | - |
| 0  | 0  | 0 |
| 0  | 1  | 0 |
| 1  | 0  | 0 |
| 1  | 1  | 1 |

**感知机公式**

```markdown

y=f(w1​x1​+w2​x2​+b)

```

| 逻辑门 | 权重 w1 w2  | 偏置 b |
| --- | ----- | ---- |
| AND | [1,1] | -1.5 |
| OR  | [1,1] | -0.5 |
| NOT | [-1]  | 0.5  |


表示 AND 门 并不只有一组权重和偏置，它有 无限组等价解，只要满足条件就行

**训练就是在无数可能解中找到一组合适的 w 和 b，让训练数据分类正确**

**机器学习是确定合适的参数的过程，人要做的是思考感知机的构造，并把训练数据交给计算机**

### 开源大模型开源的是什么

| 部分                     | 内容                                 | 是否通常开源                         |
| ---------------------- | ---------------------------------- | ------------------------------ |
| **模型权重（Weights）**      | 训练好的参数（神经网络里所有 w/b）                | ✅ 有些开源（如 LLaMA 2、MPT、Falcon 等） |
| **模型架构（Architecture）** | Transformer 层数、注意力机制、激活函数、网络拓扑     | ✅ 通常开源（论文 + 代码）                |
| **训练算法 / 数据 /训练框架**    | 优化器（Adam、LoRA）、训练策略、训练数据、并行技巧、混合精度 | ❌ 通常不开源或部分开源                   |

**DeepSeek开源程度**

| 项目              | 权重是否开源   | 架构/代码是否开源   | 训练数据/算法是否开源    |
| --------------- | -------- | ----------- | -------------- |
| **Qwen 系列**     | ✅ 多版本权重  | ✅ 推理 + 架构代码 | 部分或未完全开源       |
| **DeepSeek 系列** | ❗ 部分权重开源 | ✅ 部分基础代码    | ❌ 多数训练数据与细节不开源 |

### 垂直领域大模型的训练方法

* 利用 通用大模型的预训练知识（语言、视觉、常识）
* 再用垂直领域数据进行微调，让模型在专业领域表现更好

```markdown

通用大模型（预训练）：
   ┌───────────┐
   │语言/视觉/常识│
   └───────────┘
           │
           ▼ 微调 / LoRA / 指令调优
垂直领域大模型（专业知识）：
   ┌─────────────┐
   │医疗/法律/工业│
   └─────────────┘

```

**Anthropic 垂直模型是怎样训练的**

```markdown

           ┌───────────────────────────────┐
           │ 1️⃣ 通用大模型（开源/预训练） │
           │ - 已学通用语言/知识            │
           │ - 可直接推理                   │
           └─────────────┬─────────────────┘
                         │
                         ▼
           ┌───────────────────────────────┐
           │ 2️⃣ 数据收集与标注              │
           │ - 企业内部文档、FAQ、对话      │
           │ - 高质量标注：问题 → 答案      │
           │ ⚠ 数据成本高                   │
           └─────────────┬─────────────────┘
                         │
                         ▼
           ┌───────────────────────────────┐
           │ 3️⃣ 微调/定制训练               │
           │ - 全量微调：成本高，效果佳      │
           │ - LoRA/Adapter：小数据低成本    │
           │ - 调整权重适应行业任务          │
           │ ⚠ 算力成本高                   │
           └─────────────┬─────────────────┘
                         │
                         ▼
           ┌───────────────────────────────┐
           │ 4️⃣ 模型评估与优化               │
           │ - 验证准确率、召回率、延迟       │
           │ - 推理优化：量化/剪枝/多卡并行 │
           │ ⚠ 工程/硬件成本                 │
           └─────────────┬─────────────────┘
                         │
                         ▼
           ┌───────────────────────────────┐
           │ 5️⃣ 部署与监控                   │
           │ - 企业服务器或云端部署           │
           │ - 实时监控模型性能               │
           │ - 数据更新 → 定期微调            │
           │ ⚠ 人才与维护成本                │
           └───────────────────────────────┘

```

![vertical_model_training](/images/ai/vertical_model_training.png)

### OCR 和 LLM 图像识别的差异

| 特性   | OCR                 | LLM 图像识别/多模态模型 |
| ---- | ------------------- | -------------- |
| 主要任务 | 文字识别                | 图像理解 + 语言生成    |
| 输入   | 图像                  | 图像 + 可选文本提示    |
| 输出   | 文本（字符级）             | 文本（句子/回答）      |
| 精度关注 | 字符级精度               | 场景理解和语言表达      |
| 技术   | CNN/RNN/Transformer | 图像编码器 + LLM    |
| 应用场景 | 扫描文档、票据、证件          | 图像问答、图像描述、视觉推理 |

**OCR VS LLM 训练流程**

```markdown

OCR                       LLM
------                     -----
手工标注图片 ──► 训练集       原始文本/图像 ──► 自动生成训练任务
        │                         │
        ▼                         ▼
     OCR 模型                 LLM 模型
        │                         │
        ▼                         ▼
  图片 → 文字                提示 → 回答/生成文本

```

### 感知机无法解决XOR问题

感知机的局限性就在于它只能表示一条直线分割的空间, 对于非线性空间，需要使用曲线分割，如下图：

![perceptron_xor](/images/ai/perceptron_xor.png)

### 多层感知机

逻辑门是计算机最基本的构建块，CPU、算术逻辑单元(ALU)、寄存器等都是由大量逻辑门组合而成的

无限神经元 + 无限层 + 循环记忆 → 可以模拟图灵机 → 理论上可以实现计算机

![perceptron_multilayer](/images/ai/perceptron_multilayer.png)

## 神经元

**线性函数：** 输出值是输入值大常数倍
**非线性函数：** 函数是曲线

### 激活函数-阶跃函数

**阶跃函数**

```py

import numpy as np

import matplotlib.pyplot as plt


def step_function(x):
    return np.array(x > 0, dtype=np.int32)

x = np.arange(-5.0, 5.0, 0.1)
y = step_function(x)

plt.plot(x, y)
plt.ylim(-0.1, 1.1)
plt.title("Step Function")
plt.xlabel("X Axis")
plt.ylabel("Y Axis")
# plt.grid()
plt.show()

```

![step_function](/images/ai/step_function.png)

### Sigmoid 函数

```py

import numpy as np

import matplotlib.pyplot as plt

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

x = np.arange(-10.0, 10.0, 0.1)
y = sigmoid(x)
plt.plot(x, y)
plt.ylim(-0.1, 1.1)
plt.title("Sigmoid Function")
plt.xlabel("X Axis")
plt.ylabel("Y Axis")
# plt.grid()
plt.show()

```

![sigmoid_funtion](/images/ai/sigmoid_funtion.png)

阶跃函数 = 数字电路
Sigmoid = 模拟电路

**深度学习其实是“可微分计算机”，它不是在执行逻辑，而是在优化函数**

### 多维数组的计算

**矩阵乘法**

```py

import numpy as np

a = np.array([[1, 2, 3], [4, 5, 6]])
print(a.ndim)  # 输出数组的维度
print(a.shape)  # 输出数组的形状
print(a.dtype)  # 输出数组中元素的数据类型
print(a.size)  # 输出数组中元素的总数

# 矩阵乘法
# 1 2 3
# 4 5 6
# 乘以
# 7  8
# 9 10
# 11 12

b = np.array([[7, 8], [9, 10], [11, 12]])
c = np.dot(a, b)
print(c)  # 输出矩阵乘法的结果

# 2 x 3 乘以 3 x 2 得到 2 x 2 矩阵

# 58 64
# 139 154

# 矩阵乘法不支持交换律
d = np.dot(b, a)
print(d)  # 输出矩阵乘法的结果

# 3 x 2 乘以 2 x 3 得到 3 x 3 矩阵

# 39 54 69
# 49 68 87
# 59 82 105

# 矩阵乘法的行数和列数必须匹配，否则会报错

```

![matrix_multiplication](/images/ai/matrix_multiplication.png)

**神经网络的内积**

```py

x = np.array([1, 2])
print(x.shape)  # 输出数组的形状
y = np.array([[1, 3, 5], [2, 4,6]])
print(y.shape)  # 输出数组的形状
z = np.dot(x, y)  # 1 x 2 乘以 2 x 3 得到 1 x 3 矩阵
print(z)  # 输出矩阵乘法的结果

```

![matrix_multiplication_2](/images/ai/matrix_multiplication_2.png)

**多层神经元之间传递**

```py

import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

X = np.array([1.0, 0.5]) # 输入层的输入
W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]]) # 输入层到隐藏层的权重
B1 = np.array([0.1, 0.2, 0.3]) # 隐藏层的偏置

print("X shape:", X.shape) # （2，）
print("W1 shape:", W1.shape) # （2，3）
print("B1 shape:", B1.shape) # （3，）

A1 = np.dot(X, W1) + B1 # 计算隐藏层的加权和

Z1 = sigmoid(A1) # 计算隐藏层的输出

print(A1) # 输出隐藏层的加权和 [0.3 0.7 1.1]
print(Z1) # 输出隐藏层的输出 [0.57444252 0.66818777 0.75026011]

# 第二层（隐藏层到输出层）
W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]]) # 隐藏层到输出层的权重
B2 = np.array([0.1, 0.2]) # 输出层的偏置

A2 = np.dot(Z1, W2) + B2 # 计算输出层的加权和

Z2 = sigmoid(A2) # 计算输出层的输出

print(A2) # 输出输出层的加权和 [0.4 0.8]
print(Z2) # 输出输出层的输出 [0.59868766 0.68997448]

# 第三层（输出层到最终输出）
W3 = np.array([[0.1, 0.3], [0.2, 0.4]]) # 输出层到最终输出的权重
B3 = np.array([0.1, 0.2]) # 最终输出的偏置
A3 = np.dot(Z2, W3) + B3 # 计算最终输出的加权和
Z3 = sigmoid(A3) # 计算最终输出
print(A3) # 输出最终输出的加权和 [0.42336002 0.78658716]

print(Z3) # 输出最终输出 [0.60451623 0.68621873]

```

![multilayer_neuronal_trans](/images/ai/multilayer_neuronal_trans.png)

**封装**

```py

import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def init_network():
    network = {}
    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
    network['b1'] = np.array([0.1, 0.2, 0.3])
    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
    network['b2'] = np.array([0.1, 0.2])
    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])
    network['b3'] = np.array([0.1, 0.2])
    return network

# 前向传播函数
def forward(network, x):
    W1, W2, W3 = network['W1'], network['W2'], network['W3']
    b1, b2, b3 = network['b1'], network['b2'], network['b3']

    a1 = np.dot(x, W1) + b1
    z1 = sigmoid(a1)

    a2 = np.dot(z1, W2) + b2
    z2 = sigmoid(a2)

    a3 = np.dot(z2, W3) + b3

    return a3

network = init_network()
x = np.array([1.0, 0.5])
output = forward(network, x)
print("Final output:", output)  # 输出最终结果

```

机器学习的问题大致可以分为**分类问题**和**回归问题**

* 分类问题是数据属于哪一个类别问题。比如图像中人大性别
* 回归问题是根据输入预测一个(连续的)数值的问题。比如根据图像预测某个人大体重的问题

### softmax 函数

把一组“任意数值”变成“概率分布”

```py

def softmax(a):
    c = np.max(a)
    exp_a = np.exp(a - c)  # 防止溢出
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y

```

|   对比  | Sigmoid   | Softmax    |
| --- | --------- | ---------- |
| 作用  | 单个输出变概率   | 一组输出变概率    |
| 关系  | 彼此独立      | 彼此竞争       |
| 用途  | 二分类 / 多标签 | 多分类（只能选一个） |
| 输出和 | 不等于1      | 必定=1       |

**为什么模型不用直接输出概率？**

神经网络先输出“打分”，是因为打分是自然的、好学的、稳定的。概率是“比较后的结果”，适合最后一步再算。

```markdown

特征 → 打分(logits) → softmax → 概率 → 决策

```

## 手写数字识别

### MNIST数据集

```py

url_base = 'https://storage.googleapis.com/cvdf-datasets/mnist/'
key_file = {
    'train_img':'train-images-idx3-ubyte.gz', # 60,000 训练图像
    'train_label':'train-labels-idx1-ubyte.gz', # 60,000 训练标签
    'test_img':'t10k-images-idx3-ubyte.gz', # 10,000 测试图像
    'test_label':'t10k-labels-idx1-ubyte.gz' # 10,000 测试标签
}

```

* train_img + train_label → 用于训练模型
* test_img + test_label → 用于评估模型
* 图像是 28×28 灰度图，标签是 0~9 数字
* 都是 gzip 压缩的 IDX 格式，需要解压和解析才能使用

**minst.pkl文件的生成过程**

```markdown

┌───────────────────────────┐
│  原始手写数字扫描图像     │
│  (灰度扫描，每张不定尺寸) │
└─────────────┬─────────────┘
              │
              ▼
┌───────────────────────────┐
│  数据预处理 & 统一尺寸     │
│  - 裁剪 & 缩放到28×28      │
│  - 灰度化 (0~255)         │
└─────────────┬─────────────┘
              │
              ▼
┌───────────────────────────┐
│ 保存为 IDX 二进制文件       │
│ - 图像文件 (IDX3)：        │
│   train-images-idx3-ubyte  │
│   t10k-images-idx3-ubyte   │
│ - 标签文件 (IDX1)：        │
│   train-labels-idx1-ubyte  │
│   t10k-labels-idx1-ubyte   │
│ - 文件头+连续二进制数据     │
└─────────────┬─────────────┘
              │
              ▼
┌───────────────────────────┐
│ gzip 压缩 (.gz)           │
│ - train-images-idx3-ubyte.gz │
│ - train-labels-idx1-ubyte.gz │
│ - t10k-images-idx3-ubyte.gz  │
│ - t10k-labels-idx1-ubyte.gz  │
└─────────────┬─────────────┘
              │
              ▼
┌───────────────────────────┐
│ 解压 .gz 文件              │
│ → 得到原始 IDX 二进制文件  │
└─────────────┬─────────────┘
              │
              ▼
┌───────────────────────────┐
│ 解析 IDX 文件 → NumPy 数组 │
│ - 图像: (num_samples,28,28)│
│ - 标签: (num_samples,)     │
└─────────────┬─────────────┘
              │
              ▼
┌───────────────────────────┐
│ 可选数据处理              │
│ - 归一化 (0~1)           │
│ - 展平 (28*28 → 784)      │
│ - one-hot 编码标签         │
└─────────────┬─────────────┘
              │
              ▼
┌───────────────────────────┐
│ 保存为 mnist.pkl           │
│ - Python 字典 pickle 文件   │
│ {train_img, train_label,   │
│  test_img, test_label}     │
└───────────────────────────┘

```

### 数据推理

```py

import sys, os
import pickle
import numpy as np
import gzip
from PIL import Image

# MNIST数据保存路径
save_file = "./mnist.pkl"

# 
def _change_one_hot_label(X):
    T = np.zeros((X.size, 10))
    for idx, row in enumerate(T):
        row[X[idx]] = 1
        
    return T

def load_mnist(normalize=True, flatten=True, one_hot_label=False):
    """读入MNIST数据集
    
    Parameters
    ----------
    normalize : 将图像的像素值正规化为0.0~1.0
    one_hot_label : 
        one_hot_label为True的情况下，标签作为one-hot数组返回
        one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组
    flatten : 是否将图像展开为一维数组
    
    Returns
    -------
    (训练图像, 训练标签), (测试图像, 测试标签)
    """
    # 判断mnist.pkl文件是否存在 
    with open(save_file, 'rb') as f:
        dataset = pickle.load(f)  # 载入数据集
    
    # 进行数据处理
    if normalize:
        for key in ('train_img', 'test_img'):
            dataset[key] = dataset[key].astype(np.float32)
            dataset[key] /= 255.0
    # one-hot编码
    if one_hot_label:
        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])
        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])

    # 展开为一维数组
    if not flatten:
         for key in ('train_img', 'test_img'):
            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)

    # 返回训练数据和测试数据
    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) 

def img_show(img):
    pil_img = Image.fromarray(np.uint8(img))
    pil_img.show()

# 读入MNIST数据集
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)

img = x_train[0]
label = t_train[0]
print(label)  # 输出标签
print(img.shape)  # 输出图像形状(784,)
img = img.reshape(28, 28)  # 将一维数组形状转换为二维数组形状(28, 28)
print(img.shape)  # 输出图像形状(28, 28)
img_show(img)  # 显示图像

```

神经网络的输入层有784个神经元(28x28)算出， 输出层有10个神经元，对应10个阿拉伯数字

**推理实现**

```py

# 获取MNIST数据集
def get_data():
    (x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)
    return (x_train, t_train), (x_test, t_test)

# 学习到大权重参数
def init_network():
    with open("sample_weight.pkl", 'rb') as f:
        network = pickle.load(f)
    return network

# 预测函数
def sigmoid(x):
    # 数值稳定的 sigmoid 实现，避免在 np.exp 中出现溢出
    x = np.clip(x, -500, 500)
    return 1.0 / (1.0 + np.exp(-x))

# 前向传播中的softmax函数
def softmax(a):
    c = np.max(a)
    exp_a = np.exp(a - c)  # 防止溢出
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y

# 预测函数
def predict(network, x):
    # 神经网络中的权重
    W1, W2, W3 = network['W1'], network['W2'], network['W3']

    # 神经网络中的偏置
    b1, b2, b3 = network['b1'], network['b2'], network['b3']
    
    # 前向传播
    a1 = np.dot(x, W1) + b1
    z1 = sigmoid(a1)
    
    # 前向传播
    a2 = np.dot(z1, W2) + b2
    z2 = sigmoid(a2)
    
    # 前向传播 
    a3 = np.dot(z2, W3) + b3
    y = softmax(a3)
    
    return y

# 测试预测函数

(x_train, t_train), (x_test, t_test) = get_data()
# 使用测试集进行评估
x, t = x_test, t_test
network = init_network()

accuracy_cnt = 0
for i in range(len(x)):
    y = predict(network, x[i])
    p = np.argmax(y)  # 取得预测结果
    if p == t[i]:  # 预测正确
        accuracy_cnt += 1 # 统计正确次数

print("Accuracy:" + str(float(accuracy_cnt) / len(x)))  # 输出正确率

```

**几个概念**

* 识别精度：图别的识别率
* 正规化：比如将图像的各个像素值除以255, 将数据的值限定在0.0 ～ 1.0 的范围内
* 预处理：对神经网络的输入数据进行某种既定转换

### 批处理

输入数据和权重参数的形状(省略了偏置)

![mnist_shape](/images/ai/mnist_shape.png)

输入一个由784个元素(28x28像素的数组)的一维数组后，输出一个有10个元素的一维数组

```py

(x_train, t_train), (x_test, t_test) = get_data()
# 使用测试集进行评估
x, t = x_test, t_test

# print(x.shape)  # (10000, 784)
# print(t.shape)  # (10000,)

network = init_network()
batch_size = 100  # 每次处理的样本数量（一次送入模型预测100张图片）
accuracy_cnt = 0  # 用于累计预测正确的样本数

# 使用批处理方式对数据集进行评估
# 从第0个样本开始，每次步进 batch_size（100）
for i in range(0, len(x), batch_size):
    
    # 取出当前批次的数据，例如第0~99张图片、第100~199张图片……
    x_batch = x[i:i+batch_size]
    
    # 使用训练好的网络进行预测
    # 输出 y_batch 通常是每个样本属于各类别的概率（或得分）
    y_batch = predict(network, x_batch)
    
    # np.argmax(axis=1) 表示：
    # 在每一行（每张图片的预测结果）中，取概率最大的类别索引
    # 即模型最终预测的类别标签
    p = np.argmax(y_batch, axis=1)
    
    # 将预测结果 p 与真实标签 t[i:i+batch_size] 进行比较
    # p == t[...] 会得到一个布尔数组（True/False）
    # np.sum(...) 统计预测正确的数量
    accuracy_cnt += np.sum(p == t[i:i+batch_size])


print("Accuracy:" + str(float(accuracy_cnt) / len(x)))  # 输出正确率

```

## 神经网络的学习

学习是指从训练数据中自动获取最优权重参数的过程。学习的目的就是以损失函数为基准，找出能使函数的值达到最小的权重参数

**学习的方式**

![deep_learning](/images/ai/deep_learning.png)

| 对比项         | 传统机器学习（基于特征量）               | 深度学习（Deep Learning）          |
| ----------- | --------------------------- | ---------------------------- |
| **特征获取**    | 人工设计特征（Feature Engineering） | 自动从数据中学习特征                   |
| **模型结构**    | 浅层模型（如SVM、决策树、逻辑回归、KNN）     | 深层神经网络（CNN、RNN、Transformer等） |
| **数据需求**    | 少量数据即可                      | 大量数据才有效                      |
| **训练成本**    | 低                           | 高（需要GPU/TPU）                 |
| **表达能力**    | 有上限，难以处理复杂模式                | 极强，可拟合复杂非线性关系                |
| **复杂任务适应性** | 受限，如图像、语音、NLP难度大            | 擅长图像识别、语音、文本、生成任务            |
| **可解释性**    | 高，可追踪每个特征贡献                 | 低，黑盒性质强                      |
| **鲁棒性**     | 对噪声/变化敏感                    | 对噪声和复杂变化鲁棒性强                 |
| **工程门槛**    | 中等                          | 高，需要算力和深度学习框架                |
| **典型应用**    | 信贷风控、传感器数据分析、预测建模           | 图像识别、语音识别、OCR、自动驾驶、生成式AI     |
| **优势场景**    | 小数据、可解释、嵌入式/低算力             | 大数据、复杂模式、自动特征学习              |

深度学习有时也称为**端到端机器学习**，获得泛化能力是机器学习的最终目标

**几个概念**

* 训练数据(监督数据)
* 测试数据
* 泛化能力
* 过拟合：只对某个数据集推理有效

### 损失函数

**损失函数**是表示神经网络性能的指标

神经网络训练本质只有一件事：**最小化损失函数**

**常见损失函数**

| 分类  | 损失函数                | 用途        | 使用频率  |
| --- | ------------------- | --------- | ----- |
| 回归  | MSE                 | 数值预测      | ⭐⭐⭐⭐⭐ |
| 回归  | MAE                 | 抗异常值      | ⭐⭐⭐⭐  |
| 回归  | Huber               | MSE+MAE折中 | ⭐⭐⭐   |
| 分类  | Cross Entropy       | 多分类       | ⭐⭐⭐⭐⭐ |
| 分类  | Binary CrossEntropy | 二分类       | ⭐⭐⭐⭐⭐ |
| 分类  | Focal Loss          | 类别不平衡     | ⭐⭐⭐⭐  |
| 分割  | Dice Loss           | 医学图像      | ⭐⭐⭐⭐  |
| 分割  | IoU Loss            | 目标分割      | ⭐⭐⭐   |
| 检测  | Smooth L1           | 目标框回归     | ⭐⭐⭐⭐  |
| 检测  | GIoU/CIoU           | YOLO/检测   | ⭐⭐⭐⭐  |
| NLP | CTC Loss            | 语音/OCR    | ⭐⭐⭐   |
| NLP | KL Divergence       | 分布对齐      | ⭐⭐⭐   |

### 数据标注

MNIST 属于 监督数据集， 每张图片都有：标签（0~9）

监督数据 = 带答案的数据集
训练数据 = 从监督数据中拿出来专门用来训练的那部分

**标签（监督数据）是谁做的？**

* 人工标注
* 半自动标注
* 模型标注
* 自监督生成

AI最贵的成本 = 数据标注，甚至比算力还贵

### chatgpt 的数据是如何标注的

#### 阶段1：预训练（几乎没有人工标注）

自监督学习（self-supervised）：文本本身就是标签

**数据来源：**

* 网页文本
* 书籍
* 论文
* 代码
* Wikipedia
* 公共论坛

**任务**

给一句话，让模型预测下一个词

#### 阶段2：监督微调（SFT）

开始出现“人工标注”

1. 人类写高质量问答
2. 人类修改模型回答

#### 阶段3：RLHF（真正关键）

人类给回答打分，训练一个奖励模型

| 回答 | 人类评分 |
| -- | ---- |
| A  | 好    |
| B  | 一般   |
| C  | 差    |


真正昂贵的是这里，OpenAI、Anthropic、Google 都花巨资在这一步

**原因：**

* 需要高质量人工评审
* 需要专家
* 需要大量对比数据

#### 训练一个垂直行业 GPT 的完整数据流程

```markdown

原始行业数据
    ↓
数据清洗 & 结构化
    ↓
任务设计（问答 / 推理 / 生成）
    ↓
自监督预训练 / 继续预训练
    ↓
监督微调（SFT）
    ↓
偏好对齐（RLHF / AI Feedback）
    ↓
评测 & 安全过滤
    ↓
上线 + 数据闭环

```

| 环节       | 成本占比 |
| -------- | ---- |
| 数据清洗     | 40%  |
| 标注 & SFT | 30%  |
| RLHF     | 20%  |
| 训练算力     | 10%  |

**不是算力最贵，是数据**

### 均方误差 MSE

均方误差: MSE, Mean Squared Error

模型每预测错一点，就扣分；错得越离谱，扣分越狠, 用于数值预测

**公式**

```text

MSE = 平均(预测值 - 真实值)²

```





































