---
layout:     post
title:      智能驾驶
subtitle:   Intelligent Driving
date:       2025-02-27
author:     LXG
header-img: img/post-bg-tesla.jpg
catalog: true
tags:
    - AI
    - 行业
---

`资料来源：华金证券-智能驾驶系列`

## 华为-坚持多传感器融合方案

![huawei_ads](/images/iresearch/huawei_ads.png)

![huawei_ads_2](/images/iresearch/huawei_ads_2.png)

华为坚持多传感器方案，通过激光雷达、毫米波雷达、摄像头等多传感器互补融合感知，以达到在恶劣天气及光线不足情况下仍能有较好的感知识别表现

![huawei_ads_3](/images/iresearch/huawei_ads_3.png)

## 特斯拉-纯视觉方案

1. 自动辅助驾驶 AP
2. 增强版自动辅助驾驶 EAP
3. 完全自动驾驶 FSD

* HW3.0 8颗摄像头
* HW3.0 12颗摄像头  500万像素

![tesla_fsd](/images/iresearch/tesla_fsd.png)

![tesla_fsd_3](/images/iresearch/tesla_fsd_3.png)


**HW4.0**

* HW4.0采用三星代工的第二代FSD 7nm制程芯片，算力是HW3.0的3倍以上
* CPU内核从12个增至20个，最大频率为2.35GHz
* 使用12个摄像头（前置双目摄像头新增了2个侧视摄像头、以及1个备用摄像头。）单个高精度4D毫米波雷达、取消超声波传感器

![tesla_fsd_hw](/images/iresearch/tesla_fsd_hw.png)

### 什么是端到端

![tesla_fsd_2](/images/iresearch/tesla_fsd_2.png)

## 价格

![autodrive_price](/images/iresearch/autodrive_price.png)

## BEV 算法

BEV（Bird’s Eye View，俯视视角） 是一种用于自动驾驶的感知算法，它可以把来自摄像头、雷达等传感器的数据转换成类似“上帝视角”的俯视图，让车辆更直观地“看到”周围的环境。

BEV 的作用就是把“前方视角”转换成“上帝视角”（从上往下看），这样系统可以更清楚地理解车辆和周围环境的相对位置

![bev_transformer](/images/iresearch/bev_transformer.png)

## GOD 算法

GOD（General Occupancy Distribution，通用占用分布）算法是 特斯拉 在其自动驾驶系统中使用的一种新型环境感知算法。它的主要目标是 构建一个更加精准的三维世界模型，帮助自动驾驶系统更好地理解周围环境。

核心理念是 不再依赖物体分类，而是专注于整个环境的占用情况，让自动驾驶系统拥有更完整的 3D 世界理解能力。这种方法能让车辆更安全地应对复杂场景，成为特斯拉 FSD（全自动驾驶）系统的重要组成部分。

**GOD 算法 vs GPU 渲染游戏画面对比**

| **对比维度**         | **GOD 算法（自动驾驶）**                            | **GPU 渲染（游戏）**                           |
|----------------------|--------------------------------------------------|----------------------------------------------|
| **核心目标**         | 预测并理解真实世界的 3D 占用情况，构建自动驾驶环境模型 | 生成逼真的 3D 游戏画面，提供沉浸式视觉体验   |
| **数据来源**         | 摄像头、毫米波雷达、激光雷达等传感器                 | 预设 3D 模型、贴图、光照、物理引擎            |
| **关键计算方式**     | 深度学习推理 + 3D 占用网格                           | 3D 渲染管线（光栅化、着色、光照计算）         |
| **空间建模方式**     | 生成占用网格（Occupancy Grid），预测可行驶区域      | 构建 3D 场景，确定物体位置、碰撞检测          |
| **光栅化（Rasterization）** | 计算 3D 物体在 2D 画面中的占用情况 | 将 3D 模型转换为 2D 屏幕像素                |
| **深度学习/光照计算** | 使用神经网络预测未观测到的障碍物、车辆 | 计算光照、阴影、反射等渲染效果               |
| **连续帧预测**       | 计算环境变化，预测下一帧物体可能位置               | 计算物体运动、动画帧过渡                    |
| **物理碰撞检测**     | 通过 3D 占用网格预测障碍物、道路边界等              | 使用 BVH（包围体层次结构）、Occlusion Culling 提高渲染效率 |
| **实时性要求**       | 毫秒级决策，直接影响自动驾驶安全                    | 以帧率（FPS）为准，目标是流畅画面            |
| **最终输出**         | 可行驶区域、障碍物分布、环境预测                     | 逼真的 3D 画面，带有纹理、光影、特效         |

## 自动驾驶芯片

![autodrive_chip](/images/iresearch/autodrive_chip.png)

![autodrive_chip_2](/images/iresearch/autodrive_chip_2.png)

![audodrive_chip_3](/images/iresearch/audodrive_chip_3.png)

## 零部件国产化率

![autodrive_china](/images/iresearch/autodrive_china.png)





















