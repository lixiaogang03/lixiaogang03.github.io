---
layout:     post
title:      深度学习三
subtitle:   基于Python的理论和实现
date:       2026-02-13
author:     LXG
header-img: img/post-bg-nvida.jpg
catalog: true
tags:
    - AI
---

## 误差反向传播法

**前向传播 + 反向传播对比计算量的示意图**

![backpropagation](/images/ai/backpropagation.png)

**用迷宫来理解反向传播**

![backpropagation_2](/images/ai/backpropagation_2.png)

**计算图**

* 正向传播(forward propagation) = 预测结果
* 反向传播(backward propagation) = 分析错误原因，告诉每个神经元怎么调整

**链式法则**

* 前向传播中链式法则： 就像流水线上每个工序，把材料一步步加工成半成品 → 最终得到成品。你只关心材料怎么经过每一层，最终变成成品，不关心每个工序对最终误差的贡献。
* 反向传播中链式法则： 链式法则就像在流水线末端发现问题（成品有瑕疵），你要沿传送带回头追溯每个工序对这个问题的影响，然后告诉每台机器该如何调整。你需要知道每一层“对最终误差的贡献”，才能高效更新参数。

![backpropagation_3](/images/ai/backpropagation_3.png)

**比喻**

* 前向传播 = 你每个机器都单独调试一次 → 每次都要重新运行整个流水线
* 反向传播 = 你先让流水线走一次，把每台机器的中间状态记录下来 → 回溯计算每台机器对最终产品影响 → 不用重复跑整条线


